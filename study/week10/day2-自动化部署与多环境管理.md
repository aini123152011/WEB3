# Week 10 Day 2: è‡ªåŠ¨åŒ–éƒ¨ç½²ä¸å¤šç¯å¢ƒç®¡ç†

**é¢„è®¡å­¦ä¹ æ—¶é—´**: 6-8å°æ—¶  
**éš¾åº¦**: â­â­â­â­

## å­¦ä¹ ç›®æ ‡

é€šè¿‡æœ¬èŠ‚è¯¾ç¨‹,ä½ å°†èƒ½å¤Ÿ:
- ç†è§£å¤šç¯å¢ƒéƒ¨ç½²ç­–ç•¥å’Œæœ€ä½³å®è·µ
- å®ç°æ™ºèƒ½åˆçº¦çš„è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹
- ç®¡ç†ä¸åŒç¯å¢ƒçš„é…ç½®å’Œå¯†é’¥
- å®ç°éƒ¨ç½²éªŒè¯å’Œå›æ»šæœºåˆ¶
- æŒæ¡è“ç»¿éƒ¨ç½²å’Œé‡‘ä¸é›€å‘å¸ƒç­–ç•¥

## è¯¾ç¨‹å†…å®¹

### 1. å¤šç¯å¢ƒç®¡ç†ç­–ç•¥

#### 1.1 ç¯å¢ƒåˆ†ç±»

**æ ‡å‡†ç¯å¢ƒåˆ’åˆ†**:
```
å¼€å‘ç¯å¢ƒ (Development)
â”œâ”€â”€ æœ¬åœ°å¼€å‘ç½‘ç»œ (Hardhat/Ganache)
â”œâ”€â”€ æµ‹è¯•ç½‘ç»œ (Sepolia/Goerli)
â””â”€â”€ ç‰¹ç‚¹: å¿«é€Ÿè¿­ä»£,é¢‘ç¹éƒ¨ç½²

æµ‹è¯•ç¯å¢ƒ (Testing/Staging)
â”œâ”€â”€ å…¬å…±æµ‹è¯•ç½‘ (Sepolia/Mumbai)
â”œâ”€â”€ ç§æœ‰æµ‹è¯•ç½‘
â””â”€â”€ ç‰¹ç‚¹: æ¥è¿‘ç”Ÿäº§,å®Œæ•´æµ‹è¯•

é¢„ç”Ÿäº§ç¯å¢ƒ (Pre-production)
â”œâ”€â”€ ä¸»ç½‘åˆ†å‰
â”œâ”€â”€ å½±å­é“¾
â””â”€â”€ ç‰¹ç‚¹: æœ€ç»ˆéªŒè¯,é£é™©è¯„ä¼°

ç”Ÿäº§ç¯å¢ƒ (Production)
â”œâ”€â”€ ä¸»ç½‘ (Ethereum/Polygon/BSC)
â”œâ”€â”€ Layer2 (Arbitrum/Optimism)
â””â”€â”€ ç‰¹ç‚¹: çœŸå®èµ„é‡‘,é«˜å¯ç”¨æ€§
```

#### 1.2 ç¯å¢ƒé…ç½®ç®¡ç†

**é…ç½®æ–‡ä»¶ç»“æ„**:
```javascript
// config/environments.js
module.exports = {
  development: {
    network: 'localhost',
    rpcUrl: 'http://127.0.0.1:8545',
    chainId: 31337,
    gasPrice: 'auto',
    gas: 'auto',
    confirmations: 1,
    skipDryRun: true,
    features: {
      debugging: true,
      verbose: true,
      autoMining: true
    }
  },
  
  testnet: {
    network: 'sepolia',
    rpcUrl: process.env.SEPOLIA_RPC_URL,
    chainId: 11155111,
    gasPrice: 'auto',
    gas: 8000000,
    confirmations: 2,
    skipDryRun: false,
    timeoutBlocks: 200,
    features: {
      debugging: true,
      verbose: true,
      etherscan: {
        apiKey: process.env.ETHERSCAN_API_KEY,
        autoVerify: true
      }
    }
  },
  
  staging: {
    network: 'polygon-mumbai',
    rpcUrl: process.env.MUMBAI_RPC_URL,
    chainId: 80001,
    gasPrice: 'auto',
    gas: 8000000,
    confirmations: 3,
    skipDryRun: false,
    timeoutBlocks: 200,
    features: {
      debugging: false,
      verbose: false,
      monitoring: true,
      alerting: true,
      polygonscan: {
        apiKey: process.env.POLYGONSCAN_API_KEY,
        autoVerify: true
      }
    }
  },
  
  production: {
    network: 'mainnet',
    rpcUrl: process.env.MAINNET_RPC_URL,
    chainId: 1,
    gasPrice: process.env.GAS_PRICE || 'auto',
    gas: 8000000,
    confirmations: 5,
    skipDryRun: false,
    timeoutBlocks: 200,
    features: {
      debugging: false,
      verbose: false,
      monitoring: true,
      alerting: true,
      backup: true,
      multiSig: true,
      etherscan: {
        apiKey: process.env.ETHERSCAN_API_KEY,
        autoVerify: true
      }
    }
  }
};
```

**Hardhat å¤šç¯å¢ƒé…ç½®**:
```javascript
// hardhat.config.js
require('@nomiclabs/hardhat-waffle');
require('@nomiclabs/hardhat-etherscan');
require('hardhat-deploy');
require('hardhat-gas-reporter');
require('solidity-coverage');
require('dotenv').config();

const environments = require('./config/environments');

// è·å–ç§é’¥
function getAccounts(environment) {
  const privateKey = process.env[`${environment.toUpperCase()}_PRIVATE_KEY`];
  return privateKey ? [privateKey] : [];
}

module.exports = {
  solidity: {
    version: '0.8.19',
    settings: {
      optimizer: {
        enabled: true,
        runs: 200
      }
    }
  },
  
  networks: {
    hardhat: {
      chainId: 31337,
      forking: process.env.MAINNET_RPC_URL ? {
        url: process.env.MAINNET_RPC_URL,
        blockNumber: parseInt(process.env.FORK_BLOCK_NUMBER || '0')
      } : undefined
    },
    
    localhost: {
      url: 'http://127.0.0.1:8545',
      chainId: 31337
    },
    
    sepolia: {
      url: environments.testnet.rpcUrl,
      chainId: environments.testnet.chainId,
      accounts: getAccounts('sepolia'),
      gasPrice: environments.testnet.gasPrice,
      gas: environments.testnet.gas
    },
    
    mumbai: {
      url: environments.staging.rpcUrl,
      chainId: environments.staging.chainId,
      accounts: getAccounts('mumbai'),
      gasPrice: environments.staging.gasPrice,
      gas: environments.staging.gas
    },
    
    mainnet: {
      url: environments.production.rpcUrl,
      chainId: environments.production.chainId,
      accounts: getAccounts('mainnet'),
      gasPrice: environments.production.gasPrice,
      gas: environments.production.gas
    },
    
    polygon: {
      url: process.env.POLYGON_RPC_URL,
      chainId: 137,
      accounts: getAccounts('polygon'),
      gasPrice: 'auto',
      gas: 8000000
    }
  },
  
  namedAccounts: {
    deployer: {
      default: 0,
      1: process.env.MAINNET_DEPLOYER_ADDRESS,
      137: process.env.POLYGON_DEPLOYER_ADDRESS
    },
    admin: {
      default: 1,
      1: process.env.MAINNET_ADMIN_ADDRESS
    }
  },
  
  etherscan: {
    apiKey: {
      mainnet: process.env.ETHERSCAN_API_KEY,
      sepolia: process.env.ETHERSCAN_API_KEY,
      polygon: process.env.POLYGONSCAN_API_KEY,
      polygonMumbai: process.env.POLYGONSCAN_API_KEY
    }
  },
  
  gasReporter: {
    enabled: process.env.REPORT_GAS === 'true',
    currency: 'USD',
    coinmarketcap: process.env.COINMARKETCAP_API_KEY,
    outputFile: 'gas-report.txt',
    noColors: true
  },
  
  paths: {
    sources: './contracts',
    tests: './test',
    cache: './cache',
    artifacts: './artifacts',
    deploy: './deploy',
    deployments: './deployments'
  }
};
```

### 2. è‡ªåŠ¨åŒ–éƒ¨ç½²è„šæœ¬

#### 2.1 éƒ¨ç½²è„šæœ¬ç»“æ„

**ä½¿ç”¨ Hardhat Deploy æ’ä»¶**:
```javascript
// deploy/01_deploy_token.js
module.exports = async ({ getNamedAccounts, deployments, network }) => {
  const { deploy, log, get } = deployments;
  const { deployer } = await getNamedAccounts();
  
  log('----------------------------------------------------');
  log(`Deploying MyToken to ${network.name}`);
  log(`Deployer: ${deployer}`);
  
  // éƒ¨ç½²å‰æ£€æŸ¥
  const balance = await ethers.provider.getBalance(deployer);
  log(`Deployer balance: ${ethers.utils.formatEther(balance)} ETH`);
  
  if (balance.lt(ethers.utils.parseEther('0.1'))) {
    throw new Error('Insufficient balance for deployment');
  }
  
  // è·å–æ„é€ å‡½æ•°å‚æ•°
  const args = [
    'MyToken',
    'MTK',
    ethers.utils.parseEther('1000000')
  ];
  
  // éƒ¨ç½²åˆçº¦
  const token = await deploy('MyToken', {
    from: deployer,
    args: args,
    log: true,
    waitConfirmations: network.config.confirmations || 1,
    skipIfAlreadyDeployed: true
  });
  
  log(`MyToken deployed at: ${token.address}`);
  
  // éªŒè¯åˆçº¦
  if (network.name !== 'hardhat' && network.name !== 'localhost') {
    log('Waiting for block confirmations...');
    await token.deployTransaction.wait(6);
    await verify(token.address, args);
  }
  
  // ä¿å­˜éƒ¨ç½²ä¿¡æ¯
  await saveDeploymentInfo(network.name, 'MyToken', token);
  
  log('----------------------------------------------------');
};

module.exports.tags = ['Token', 'All'];
```

**éƒ¨ç½² NFT åˆçº¦**:
```javascript
// deploy/02_deploy_nft.js
module.exports = async ({ getNamedAccounts, deployments, network }) => {
  const { deploy, log, get } = deployments;
  const { deployer, admin } = await getNamedAccounts();
  
  log('----------------------------------------------------');
  log(`Deploying MyNFT to ${network.name}`);
  
  // è·å–ä¾èµ–åˆçº¦
  const token = await get('MyToken');
  
  const args = [
    'MyNFT',
    'MNFT',
    'https://api.mynft.com/metadata/',
    token.address,
    admin
  ];
  
  const nft = await deploy('MyNFT', {
    from: deployer,
    args: args,
    log: true,
    waitConfirmations: network.config.confirmations || 1,
    proxy: {
      proxyContract: 'OpenZeppelinTransparentProxy',
      execute: {
        init: {
          methodName: 'initialize',
          args: args
        }
      }
    }
  });
  
  log(`MyNFT deployed at: ${nft.address}`);
  log(`Implementation: ${nft.implementation}`);
  log(`Proxy Admin: ${nft.proxyAdmin}`);
  
  // é…ç½®è§’è‰²
  if (network.name !== 'hardhat') {
    await setupRoles(nft, deployer, admin);
  }
  
  // éªŒè¯åˆçº¦
  if (network.name !== 'hardhat' && network.name !== 'localhost') {
    await nft.deployTransaction.wait(6);
    await verify(nft.implementation, args);
  }
  
  log('----------------------------------------------------');
};

module.exports.tags = ['NFT', 'All'];
module.exports.dependencies = ['Token'];
```

**å¤æ‚ç³»ç»Ÿéƒ¨ç½²**:
```javascript
// deploy/03_deploy_marketplace.js
module.exports = async ({ getNamedAccounts, deployments, network, ethers }) => {
  const { deploy, log, get, execute } = deployments;
  const { deployer, admin } = await getNamedAccounts();
  
  log('----------------------------------------------------');
  log('Deploying Marketplace System');
  
  // 1. éƒ¨ç½²å¸‚åœºåˆçº¦
  const marketplace = await deploy('NFTMarketplace', {
    from: deployer,
    args: [],
    log: true,
    waitConfirmations: network.config.confirmations || 1
  });
  
  // 2. éƒ¨ç½²æ‹å–åˆçº¦
  const auction = await deploy('NFTAuction', {
    from: deployer,
    args: [marketplace.address],
    log: true,
    waitConfirmations: network.config.confirmations || 1
  });
  
  // 3. éƒ¨ç½²ç‰ˆç¨ç®¡ç†åˆçº¦
  const royalty = await deploy('RoyaltyManager', {
    from: deployer,
    args: [],
    log: true,
    waitConfirmations: network.config.confirmations || 1
  });
  
  // 4. é…ç½®åˆçº¦å…³ç³»
  log('Configuring contract relationships...');
  
  await execute(
    'NFTMarketplace',
    { from: deployer, log: true },
    'setAuctionContract',
    auction.address
  );
  
  await execute(
    'NFTMarketplace',
    { from: deployer, log: true },
    'setRoyaltyManager',
    royalty.address
  );
  
  await execute(
    'NFTAuction',
    { from: deployer, log: true },
    'setRoyaltyManager',
    royalty.address
  );
  
  // 5. è®¾ç½®æ‰‹ç»­è´¹
  const feePercent = 250; // 2.5%
  await execute(
    'NFTMarketplace',
    { from: deployer, log: true },
    'setFeePercent',
    feePercent
  );
  
  // 6. è½¬ç§»æ‰€æœ‰æƒ
  if (admin !== deployer) {
    log('Transferring ownership to admin...');
    await execute(
      'NFTMarketplace',
      { from: deployer, log: true },
      'transferOwnership',
      admin
    );
    
    await execute(
      'NFTAuction',
      { from: deployer, log: true },
      'transferOwnership',
      admin
    );
    
    await execute(
      'RoyaltyManager',
      { from: deployer, log: true },
      'transferOwnership',
      admin
    );
  }
  
  // 7. ä¿å­˜éƒ¨ç½²æ¸…å•
  await saveDeploymentManifest(network.name, {
    marketplace: marketplace.address,
    auction: auction.address,
    royalty: royalty.address,
    deployer: deployer,
    admin: admin,
    feePercent: feePercent,
    timestamp: Date.now()
  });
  
  log('Marketplace system deployed successfully');
  log('----------------------------------------------------');
};

module.exports.tags = ['Marketplace', 'All'];
module.exports.dependencies = ['NFT'];
```

#### 2.2 éƒ¨ç½²å·¥å…·å‡½æ•°

**éªŒè¯åˆçº¦**:
```javascript
// scripts/utils/verify.js
const { run } = require('hardhat');

async function verify(contractAddress, args) {
  console.log('Verifying contract...');
  try {
    await run('verify:verify', {
      address: contractAddress,
      constructorArguments: args
    });
    console.log('Contract verified successfully');
  } catch (error) {
    if (error.message.toLowerCase().includes('already verified')) {
      console.log('Contract already verified');
    } else {
      console.error('Verification failed:', error);
    }
  }
}

module.exports = { verify };
```

**ä¿å­˜éƒ¨ç½²ä¿¡æ¯**:
```javascript
// scripts/utils/deployment.js
const fs = require('fs');
const path = require('path');

async function saveDeploymentInfo(network, contractName, deployment) {
  const deploymentDir = path.join(__dirname, '../../deployments-info', network);
  
  if (!fs.existsSync(deploymentDir)) {
    fs.mkdirSync(deploymentDir, { recursive: true });
  }
  
  const info = {
    name: contractName,
    address: deployment.address,
    implementation: deployment.implementation,
    transactionHash: deployment.transactionHash,
    deployer: deployment.receipt.from,
    blockNumber: deployment.receipt.blockNumber,
    gasUsed: deployment.receipt.gasUsed.toString(),
    timestamp: new Date().toISOString()
  };
  
  const filePath = path.join(deploymentDir, `${contractName}.json`);
  fs.writeFileSync(filePath, JSON.stringify(info, null, 2));
  
  console.log(`Deployment info saved to ${filePath}`);
}

async function saveDeploymentManifest(network, data) {
  const filePath = path.join(
    __dirname,
    '../../deployments-info',
    network,
    'manifest.json'
  );
  
  let manifest = {};
  if (fs.existsSync(filePath)) {
    manifest = JSON.parse(fs.readFileSync(filePath, 'utf8'));
  }
  
  manifest = { ...manifest, ...data };
  fs.writeFileSync(filePath, JSON.stringify(manifest, null, 2));
  
  console.log(`Manifest updated: ${filePath}`);
}

async function loadDeploymentInfo(network, contractName) {
  const filePath = path.join(
    __dirname,
    '../../deployments-info',
    network,
    `${contractName}.json`
  );
  
  if (!fs.existsSync(filePath)) {
    throw new Error(`Deployment info not found for ${contractName} on ${network}`);
  }
  
  return JSON.parse(fs.readFileSync(filePath, 'utf8'));
}

module.exports = {
  saveDeploymentInfo,
  saveDeploymentManifest,
  loadDeploymentInfo
};
```

**è®¾ç½®è§’è‰²å’Œæƒé™**:
```javascript
// scripts/utils/roles.js
async function setupRoles(deployment, deployer, admin) {
  const contract = await ethers.getContractAt(
    deployment.abi,
    deployment.address
  );
  
  console.log('Setting up roles...');
  
  // æˆäºˆç®¡ç†å‘˜è§’è‰²
  const ADMIN_ROLE = await contract.DEFAULT_ADMIN_ROLE();
  const MINTER_ROLE = await contract.MINTER_ROLE();
  const PAUSER_ROLE = await contract.PAUSER_ROLE();
  
  const hasAdminRole = await contract.hasRole(ADMIN_ROLE, admin);
  if (!hasAdminRole) {
    const tx = await contract.grantRole(ADMIN_ROLE, admin);
    await tx.wait();
    console.log(`Granted ADMIN_ROLE to ${admin}`);
  }
  
  // æˆäºˆé“¸é€ è€…è§’è‰²
  const hasMinterRole = await contract.hasRole(MINTER_ROLE, admin);
  if (!hasMinterRole) {
    const tx = await contract.grantRole(MINTER_ROLE, admin);
    await tx.wait();
    console.log(`Granted MINTER_ROLE to ${admin}`);
  }
  
  // æˆäºˆæš‚åœè€…è§’è‰²
  const hasPauserRole = await contract.hasRole(PAUSER_ROLE, admin);
  if (!hasPauserRole) {
    const tx = await contract.grantRole(PAUSER_ROLE, admin);
    await tx.wait();
    console.log(`Granted PAUSER_ROLE to ${admin}`);
  }
  
  // æ’¤é”€éƒ¨ç½²è€…çš„é“¸é€ æƒé™(å¦‚æœéœ€è¦)
  if (deployer !== admin) {
    const deployerHasMinter = await contract.hasRole(MINTER_ROLE, deployer);
    if (deployerHasMinter) {
      const tx = await contract.revokeRole(MINTER_ROLE, deployer);
      await tx.wait();
      console.log(`Revoked MINTER_ROLE from deployer ${deployer}`);
    }
  }
  
  console.log('Roles setup completed');
}

module.exports = { setupRoles };
```

### 3. GitHub Actions è‡ªåŠ¨éƒ¨ç½²

#### 3.1 æµ‹è¯•ç½‘è‡ªåŠ¨éƒ¨ç½²

```yaml
# .github/workflows/deploy-testnet.yaml
name: Deploy to Testnet

on:
  push:
    branches:
      - develop
  workflow_dispatch:
    inputs:
      network:
        description: 'Target network'
        required: true
        default: 'sepolia'
        type: choice
        options:
          - sepolia
          - mumbai
          - goerli

env:
  NODE_VERSION: '18'

jobs:
  deploy:
    name: Deploy Contracts
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Compile contracts
        run: npm run compile
      
      - name: Run tests
        run: npm test
      
      - name: Set network
        id: network
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "NETWORK=${{ github.event.inputs.network }}" >> $GITHUB_ENV
          else
            echo "NETWORK=sepolia" >> $GITHUB_ENV
          fi
      
      - name: Deploy to ${{ env.NETWORK }}
        env:
          SEPOLIA_RPC_URL: ${{ secrets.SEPOLIA_RPC_URL }}
          SEPOLIA_PRIVATE_KEY: ${{ secrets.SEPOLIA_PRIVATE_KEY }}
          MUMBAI_RPC_URL: ${{ secrets.MUMBAI_RPC_URL }}
          MUMBAI_PRIVATE_KEY: ${{ secrets.MUMBAI_PRIVATE_KEY }}
          GOERLI_RPC_URL: ${{ secrets.GOERLI_RPC_URL }}
          GOERLI_PRIVATE_KEY: ${{ secrets.GOERLI_PRIVATE_KEY }}
          ETHERSCAN_API_KEY: ${{ secrets.ETHERSCAN_API_KEY }}
          POLYGONSCAN_API_KEY: ${{ secrets.POLYGONSCAN_API_KEY }}
        run: |
          npx hardhat deploy --network ${{ env.NETWORK }} --tags All
      
      - name: Verify contracts
        env:
          ETHERSCAN_API_KEY: ${{ secrets.ETHERSCAN_API_KEY }}
          POLYGONSCAN_API_KEY: ${{ secrets.POLYGONSCAN_API_KEY }}
        run: |
          npx hardhat --network ${{ env.NETWORK }} etherscan-verify
      
      - name: Generate deployment report
        run: |
          npm run deployment:report -- --network ${{ env.NETWORK }}
      
      - name: Upload deployment artifacts
        uses: actions/upload-artifact@v3
        with:
          name: deployment-${{ env.NETWORK }}-${{ github.sha }}
          path: |
            deployments/
            deployments-info/
            deployment-report.md
      
      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('deployment-report.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## Deployment Report\n\n${report}`
            });
      
      - name: Notify on failure
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Testnet deployment failed!'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

#### 3.2 ä¸»ç½‘éƒ¨ç½²å·¥ä½œæµ

```yaml
# .github/workflows/deploy-mainnet.yaml
name: Deploy to Mainnet

on:
  release:
    types: [published]
  workflow_dispatch:
    inputs:
      confirm:
        description: 'Type "DEPLOY" to confirm mainnet deployment'
        required: true
      network:
        description: 'Target mainnet'
        required: true
        default: 'mainnet'
        type: choice
        options:
          - mainnet
          - polygon
          - arbitrum
          - optimism

jobs:
  pre-deployment-checks:
    name: Pre-deployment Checks
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Verify confirmation
        if: github.event_name == 'workflow_dispatch'
        run: |
          if [ "${{ github.event.inputs.confirm }}" != "DEPLOY" ]; then
            echo "Deployment not confirmed!"
            exit 1
          fi
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Run full test suite
        run: npm run test:full
      
      - name: Run security checks
        run: |
          npm run security:check
          npm run audit
      
      - name: Check gas costs
        run: npm run gas:report
      
      - name: Generate coverage report
        run: npm run coverage
      
      - name: Upload reports
        uses: actions/upload-artifact@v3
        with:
          name: pre-deployment-reports
          path: |
            coverage/
            gas-report.txt
            security-report.json

  approve-deployment:
    name: Manual Approval
    runs-on: ubuntu-latest
    needs: pre-deployment-checks
    environment:
      name: production
      url: https://etherscan.io
    
    steps:
      - name: Wait for approval
        run: echo "Deployment approved"

  deploy-mainnet:
    name: Deploy to Mainnet
    runs-on: ubuntu-latest
    needs: approve-deployment
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '18'
          cache: 'npm'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Set network
        id: network
        run: |
          if [ "${{ github.event_name }}" == "workflow_dispatch" ]; then
            echo "NETWORK=${{ github.event.inputs.network }}" >> $GITHUB_ENV
          else
            echo "NETWORK=mainnet" >> $GITHUB_ENV
          fi
      
      - name: Check deployer balance
        env:
          MAINNET_RPC_URL: ${{ secrets.MAINNET_RPC_URL }}
          MAINNET_PRIVATE_KEY: ${{ secrets.MAINNET_PRIVATE_KEY }}
        run: |
          node scripts/check-balance.js --network ${{ env.NETWORK }}
      
      - name: Deploy contracts
        env:
          MAINNET_RPC_URL: ${{ secrets.MAINNET_RPC_URL }}
          MAINNET_PRIVATE_KEY: ${{ secrets.MAINNET_PRIVATE_KEY }}
          POLYGON_RPC_URL: ${{ secrets.POLYGON_RPC_URL }}
          POLYGON_PRIVATE_KEY: ${{ secrets.POLYGON_PRIVATE_KEY }}
          ARBITRUM_RPC_URL: ${{ secrets.ARBITRUM_RPC_URL }}
          ARBITRUM_PRIVATE_KEY: ${{ secrets.ARBITRUM_PRIVATE_KEY }}
          OPTIMISM_RPC_URL: ${{ secrets.OPTIMISM_RPC_URL }}
          OPTIMISM_PRIVATE_KEY: ${{ secrets.OPTIMISM_PRIVATE_KEY }}
          ETHERSCAN_API_KEY: ${{ secrets.ETHERSCAN_API_KEY }}
          POLYGONSCAN_API_KEY: ${{ secrets.POLYGONSCAN_API_KEY }}
          ARBISCAN_API_KEY: ${{ secrets.ARBISCAN_API_KEY }}
          OPTIMISTIC_ETHERSCAN_API_KEY: ${{ secrets.OPTIMISTIC_ETHERSCAN_API_KEY }}
          GAS_PRICE: ${{ secrets.GAS_PRICE }}
        run: |
          npx hardhat deploy \
            --network ${{ env.NETWORK }} \
            --tags All \
            --export deployments-export.json
      
      - name: Verify contracts
        run: |
          npx hardhat --network ${{ env.NETWORK }} etherscan-verify
      
      - name: Run post-deployment tests
        run: |
          npm run test:integration -- --network ${{ env.NETWORK }}
      
      - name: Generate deployment documentation
        run: |
          node scripts/generate-docs.js --network ${{ env.NETWORK }}
      
      - name: Backup deployment data
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          npm run backup:deployment -- --network ${{ env.NETWORK }}
      
      - name: Create deployment summary
        run: |
          node scripts/create-summary.js --network ${{ env.NETWORK }}
      
      - name: Upload deployment artifacts
        uses: actions/upload-artifact@v3
        with:
          name: mainnet-deployment-${{ github.sha }}
          path: |
            deployments/
            deployments-info/
            deployments-export.json
            deployment-docs/
      
      - name: Notify success
        uses: 8398a7/action-slack@v3
        with:
          status: success
          text: 'Mainnet deployment successful! ğŸš€'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
      
      - name: Notify failure
        if: failure()
        uses: 8398a7/action-slack@v3
        with:
          status: failure
          text: 'Mainnet deployment failed! âš ï¸'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}

  post-deployment:
    name: Post-deployment Tasks
    runs-on: ubuntu-latest
    needs: deploy-mainnet
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Setup monitoring
        run: |
          node scripts/setup-monitoring.js --network ${{ env.NETWORK }}
      
      - name: Configure alerts
        run: |
          node scripts/configure-alerts.js --network ${{ env.NETWORK }}
      
      - name: Update documentation
        run: |
          node scripts/update-docs.js
      
      - name: Create GitHub release notes
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const summary = fs.readFileSync('deployment-summary.md', 'utf8');
            await github.rest.repos.updateRelease({
              owner: context.repo.owner,
              repo: context.repo.repo,
              release_id: context.payload.release.id,
              body: context.payload.release.body + '\n\n## Deployment Summary\n\n' + summary
            });
```

### 4. éƒ¨ç½²éªŒè¯å’Œå›æ»š

#### 4.1 éƒ¨ç½²åéªŒè¯è„šæœ¬

```javascript
// scripts/verify-deployment.js
const hre = require('hardhat');
const { loadDeploymentInfo } = require('./utils/deployment');

async function verifyDeployment(network, contractName) {
  console.log(`Verifying ${contractName} deployment on ${network}...`);
  
  // 1. åŠ è½½éƒ¨ç½²ä¿¡æ¯
  const deployment = await loadDeploymentInfo(network, contractName);
  console.log(`Contract address: ${deployment.address}`);
  
  // 2. éªŒè¯åˆçº¦ä»£ç 
  const code = await hre.ethers.provider.getCode(deployment.address);
  if (code === '0x') {
    throw new Error('No contract code at address');
  }
  console.log('âœ“ Contract code exists');
  
  // 3. è·å–åˆçº¦å®ä¾‹
  const contract = await hre.ethers.getContractAt(
    contractName,
    deployment.address
  );
  
  // 4. éªŒè¯åˆçº¦çŠ¶æ€
  try {
    const name = await contract.name();
    console.log(`âœ“ Contract name: ${name}`);
    
    const symbol = await contract.symbol();
    console.log(`âœ“ Contract symbol: ${symbol}`);
    
    const owner = await contract.owner();
    console.log(`âœ“ Contract owner: ${owner}`);
    
    const paused = await contract.paused();
    console.log(`âœ“ Contract paused: ${paused}`);
  } catch (error) {
    console.error('Contract state verification failed:', error);
    throw error;
  }
  
  // 5. éªŒè¯æƒé™é…ç½®
  const ADMIN_ROLE = await contract.DEFAULT_ADMIN_ROLE();
  const MINTER_ROLE = await contract.MINTER_ROLE();
  
  const adminAddress = process.env[`${network.toUpperCase()}_ADMIN_ADDRESS`];
  const hasAdminRole = await contract.hasRole(ADMIN_ROLE, adminAddress);
  const hasMinterRole = await contract.hasRole(MINTER_ROLE, adminAddress);
  
  if (!hasAdminRole) {
    throw new Error(`Admin does not have ADMIN_ROLE`);
  }
  console.log('âœ“ Admin role configured correctly');
  
  if (!hasMinterRole) {
    throw new Error(`Admin does not have MINTER_ROLE`);
  }
  console.log('âœ“ Minter role configured correctly');
  
  // 6. æµ‹è¯•åŸºæœ¬åŠŸèƒ½
  console.log('Testing basic functionality...');
  
  const signer = await hre.ethers.getSigner();
  const balance = await contract.balanceOf(signer.address);
  console.log(`âœ“ Balance query works: ${balance.toString()}`);
  
  // 7. éªŒè¯äº‹ä»¶
  const filter = contract.filters.Transfer();
  const events = await contract.queryFilter(filter, -100);
  console.log(`âœ“ Found ${events.length} Transfer events in last 100 blocks`);
  
  console.log('\nâœ… Deployment verification completed successfully');
  return true;
}

async function verifySystemDeployment(network) {
  console.log(`\n${'='.repeat(60)}`);
  console.log(`Verifying complete system deployment on ${network}`);
  console.log('='.repeat(60));
  
  const contracts = ['MyToken', 'MyNFT', 'NFTMarketplace', 'NFTAuction'];
  
  for (const contract of contracts) {
    try {
      await verifyDeployment(network, contract);
    } catch (error) {
      console.error(`\nâŒ Verification failed for ${contract}:`, error.message);
      return false;
    }
  }
  
  // éªŒè¯åˆçº¦ä¹‹é—´çš„å…³ç³»
  console.log('\nVerifying contract relationships...');
  
  const marketplace = await hre.ethers.getContract('NFTMarketplace');
  const auction = await hre.ethers.getContract('NFTAuction');
  
  const auctionAddress = await marketplace.auctionContract();
  if (auctionAddress !== auction.address) {
    throw new Error('Auction contract not properly linked to marketplace');
  }
  console.log('âœ“ Contract relationships verified');
  
  console.log('\nâœ… System deployment verification completed successfully');
  return true;
}

// ä¸»å‡½æ•°
async function main() {
  const network = process.env.HARDHAT_NETWORK || hre.network.name;
  const success = await verifySystemDeployment(network);
  
  if (!success) {
    process.exit(1);
  }
}

if (require.main === module) {
  main()
    .then(() => process.exit(0))
    .catch((error) => {
      console.error(error);
      process.exit(1);
    });
}

module.exports = { verifyDeployment, verifySystemDeployment };
```

#### 4.2 å›æ»šæœºåˆ¶

```javascript
// scripts/rollback.js
const hre = require('hardhat');
const fs = require('fs');
const path = require('path');

async function loadBackup(network, timestamp) {
  const backupPath = path.join(
    __dirname,
    '../backups',
    network,
    `${timestamp}.json`
  );
  
  if (!fs.existsSync(backupPath)) {
    throw new Error(`Backup not found: ${backupPath}`);
  }
  
  return JSON.parse(fs.readFileSync(backupPath, 'utf8'));
}

async function createBackup(network) {
  const timestamp = Date.now();
  const backupDir = path.join(__dirname, '../backups', network);
  
  if (!fs.existsSync(backupDir)) {
    fs.mkdirSync(backupDir, { recursive: true });
  }
  
  // è¯»å–å½“å‰éƒ¨ç½²çŠ¶æ€
  const deployments = {};
  const deploymentDir = path.join(__dirname, '../deployments', network);
  
  if (fs.existsSync(deploymentDir)) {
    const files = fs.readdirSync(deploymentDir);
    for (const file of files) {
      if (file.endsWith('.json') && file !== '.chainId') {
        const content = fs.readFileSync(
          path.join(deploymentDir, file),
          'utf8'
        );
        deployments[file] = JSON.parse(content);
      }
    }
  }
  
  const backup = {
    timestamp,
    network,
    deployments,
    git: {
      commit: process.env.GITHUB_SHA || 'unknown',
      branch: process.env.GITHUB_REF || 'unknown'
    }
  };
  
  const backupPath = path.join(backupDir, `${timestamp}.json`);
  fs.writeFileSync(backupPath, JSON.stringify(backup, null, 2));
  
  console.log(`Backup created: ${backupPath}`);
  return timestamp;
}

async function rollbackTo(network, timestamp) {
  console.log(`Rolling back ${network} to ${timestamp}...`);
  
  // 1. åˆ›å»ºå½“å‰çŠ¶æ€å¤‡ä»½
  console.log('Creating backup of current state...');
  await createBackup(network);
  
  // 2. åŠ è½½ç›®æ ‡å¤‡ä»½
  console.log('Loading target backup...');
  const backup = await loadBackup(network, timestamp);
  
  // 3. æ¢å¤éƒ¨ç½²æ–‡ä»¶
  console.log('Restoring deployment files...');
  const deploymentDir = path.join(__dirname, '../deployments', network);
  
  if (!fs.existsSync(deploymentDir)) {
    fs.mkdirSync(deploymentDir, { recursive: true });
  }
  
  for (const [filename, content] of Object.entries(backup.deployments)) {
    const filePath = path.join(deploymentDir, filename);
    fs.writeFileSync(filePath, JSON.stringify(content, null, 2));
    console.log(`âœ“ Restored ${filename}`);
  }
  
  console.log('Rollback completed successfully');
}

async function listBackups(network) {
  const backupDir = path.join(__dirname, '../backups', network);
  
  if (!fs.existsSync(backupDir)) {
    console.log('No backups found');
    return [];
  }
  
  const files = fs.readdirSync(backupDir);
  const backups = [];
  
  for (const file of files) {
    if (file.endsWith('.json')) {
      const backup = JSON.parse(
        fs.readFileSync(path.join(backupDir, file), 'utf8')
      );
      backups.push({
        timestamp: backup.timestamp,
        date: new Date(backup.timestamp).toISOString(),
        commit: backup.git.commit,
        contracts: Object.keys(backup.deployments).length
      });
    }
  }
  
  backups.sort((a, b) => b.timestamp - a.timestamp);
  
  console.log('\nAvailable backups:');
  console.log('â”€'.repeat(80));
  backups.forEach((backup, index) => {
    console.log(
      `${index + 1}. ${backup.date} | ` +
      `Commit: ${backup.commit.substring(0, 8)} | ` +
      `Contracts: ${backup.contracts}`
    );
  });
  console.log('â”€'.repeat(80));
  
  return backups;
}

// ä¸»å‡½æ•°
async function main() {
  const command = process.argv[2];
  const network = process.env.HARDHAT_NETWORK || hre.network.name;
  
  switch (command) {
    case 'backup':
      await createBackup(network);
      break;
    
    case 'list':
      await listBackups(network);
      break;
    
    case 'rollback':
      const timestamp = process.argv[3];
      if (!timestamp) {
        console.error('Please provide a timestamp');
        process.exit(1);
      }
      await rollbackTo(network, parseInt(timestamp));
      break;
    
    default:
      console.log('Usage:');
      console.log('  npm run rollback backup');
      console.log('  npm run rollback list');
      console.log('  npm run rollback rollback <timestamp>');
      process.exit(1);
  }
}

if (require.main === module) {
  main()
    .then(() => process.exit(0))
    .catch((error) => {
      console.error(error);
      process.exit(1);
    });
}

module.exports = {
  createBackup,
  rollbackTo,
  listBackups
};
```

### 5. é«˜çº§éƒ¨ç½²ç­–ç•¥

#### 5.1 è“ç»¿éƒ¨ç½²

```javascript
// scripts/blue-green-deployment.js
const hre = require('hardhat');

async function blueGreenDeployment(contractName, args) {
  console.log(`Starting blue-green deployment for ${contractName}...`);
  
  // 1. è·å–å½“å‰æ´»è·ƒçš„åˆçº¦ (è“)
  const registry = await hre.ethers.getContract('ContractRegistry');
  const blueAddress = await registry.getContract(contractName);
  
  console.log(`Current (blue) contract: ${blueAddress}`);
  
  // 2. éƒ¨ç½²æ–°ç‰ˆæœ¬ (ç»¿)
  console.log('Deploying new (green) version...');
  const Contract = await hre.ethers.getContractFactory(contractName);
  const greenContract = await Contract.deploy(...args);
  await greenContract.deployed();
  
  console.log(`New (green) contract deployed: ${greenContract.address}`);
  
  // 3. éªŒè¯æ–°åˆçº¦
  console.log('Verifying new contract...');
  await verifyDeployment(hre.network.name, contractName);
  
  // 4. è¿ç§»çŠ¶æ€(å¦‚æœéœ€è¦)
  if (blueAddress !== hre.ethers.constants.AddressZero) {
    console.log('Migrating state...');
    await migrateState(blueAddress, greenContract.address);
  }
  
  // 5. åˆ‡æ¢æµé‡åˆ°æ–°åˆçº¦
  console.log('Switching traffic to green...');
  const tx = await registry.updateContract(contractName, greenContract.address);
  await tx.wait();
  
  console.log('Traffic switched to green contract');
  
  // 6. ç›‘æ§æ–°åˆçº¦
  console.log('Monitoring new contract...');
  const healthy = await monitorContract(greenContract.address, 300); // 5åˆ†é’Ÿ
  
  if (!healthy) {
    // å›æ»šåˆ°è“è‰²ç‰ˆæœ¬
    console.error('Health check failed! Rolling back...');
    const rollbackTx = await registry.updateContract(contractName, blueAddress);
    await rollbackTx.wait();
    throw new Error('Deployment rolled back due to health check failure');
  }
  
  console.log('Health check passed! Deployment successful');
  
  // 7. ä¿ç•™è“è‰²ç‰ˆæœ¬ä¸€æ®µæ—¶é—´ä»¥ä¾¿å¿«é€Ÿå›æ»š
  console.log(`Blue contract ${blueAddress} will be kept for 24 hours`);
  
  return {
    blue: blueAddress,
    green: greenContract.address,
    registry: registry.address
  };
}

async function migrateState(oldAddress, newAddress) {
  // å®ç°çŠ¶æ€è¿ç§»é€»è¾‘
  const oldContract = await hre.ethers.getContractAt('MyContract', oldAddress);
  const newContract = await hre.ethers.getContractAt('MyContract', newAddress);
  
  // ç¤ºä¾‹: è¿ç§»æ‰€æœ‰è€…åˆ—è¡¨
  const ownerCount = await oldContract.getOwnerCount();
  for (let i = 0; i < ownerCount; i++) {
    const owner = await oldContract.getOwnerAt(i);
    const tx = await newContract.addOwner(owner);
    await tx.wait();
    console.log(`Migrated owner ${i + 1}/${ownerCount}: ${owner}`);
  }
}

async function monitorContract(address, duration) {
  const contract = await hre.ethers.getContractAt('MyContract', address);
  const startTime = Date.now();
  const endTime = startTime + duration * 1000;
  
  while (Date.now() < endTime) {
    try {
      // æ£€æŸ¥åˆçº¦æ˜¯å¦å“åº”
      await contract.healthCheck();
      
      // æ£€æŸ¥é”™è¯¯ç‡
      const errorCount = await contract.getErrorCount();
      if (errorCount > 10) {
        console.error('Too many errors detected');
        return false;
      }
      
      // ç­‰å¾…ä¸‹ä¸€æ¬¡æ£€æŸ¥
      await new Promise(resolve => setTimeout(resolve, 10000)); // 10ç§’
    } catch (error) {
      console.error('Health check failed:', error);
      return false;
    }
  }
  
  return true;
}

module.exports = { blueGreenDeployment };
```

#### 5.2 é‡‘ä¸é›€å‘å¸ƒ

```javascript
// scripts/canary-deployment.js
const hre = require('hardhat');

async function canaryDeployment(contractName, args, canaryPercent = 10) {
  console.log(`Starting canary deployment for ${contractName}...`);
  console.log(`Canary traffic percentage: ${canaryPercent}%`);
  
  // 1. è·å–å½“å‰ç”Ÿäº§åˆçº¦
  const registry = await hre.ethers.getContract('ContractRegistry');
  const productionAddress = await registry.getContract(contractName);
  
  // 2. éƒ¨ç½²é‡‘ä¸é›€ç‰ˆæœ¬
  console.log('Deploying canary version...');
  const Contract = await hre.ethers.getContractFactory(contractName);
  const canaryContract = await Contract.deploy(...args);
  await canaryContract.deployed();
  
  console.log(`Canary deployed: ${canaryContract.address}`);
  
  // 3. æ³¨å†Œé‡‘ä¸é›€ç‰ˆæœ¬
  const tx = await registry.setCanary(
    contractName,
    canaryContract.address,
    canaryPercent
  );
  await tx.wait();
  
  // 4. é€æ­¥å¢åŠ æµé‡
  const steps = [10, 25, 50, 75, 100];
  
  for (const percent of steps) {
    if (percent <= canaryPercent) continue;
    
    console.log(`\nIncreasing canary traffic to ${percent}%...`);
    
    // ç›‘æ§æŒ‡æ ‡
    const metrics = await collectMetrics(canaryContract.address, 300);
    
    if (!isHealthy(metrics)) {
      console.error('Canary metrics unhealthy! Rolling back...');
      await registry.removeCanary(contractName);
      throw new Error('Canary deployment failed');
    }
    
    // å¢åŠ æµé‡
    const updateTx = await registry.setCanary(
      contractName,
      canaryContract.address,
      percent
    );
    await updateTx.wait();
    
    console.log(`Traffic increased to ${percent}%`);
  }
  
  // 5. å®Œå…¨åˆ‡æ¢åˆ°é‡‘ä¸é›€ç‰ˆæœ¬
  console.log('\nPromoting canary to production...');
  const promoteTx = await registry.promoteCanary(contractName);
  await promoteTx.wait();
  
  console.log('Canary successfully promoted to production!');
  
  return {
    old: productionAddress,
    new: canaryContract.address
  };
}

async function collectMetrics(address, duration) {
  // æ”¶é›†åˆçº¦æŒ‡æ ‡
  return {
    errorRate: 0.01,
    avgResponseTime: 150,
    successRate: 0.99,
    gasUsage: 50000
  };
}

function isHealthy(metrics) {
  return (
    metrics.errorRate < 0.05 &&
    metrics.avgResponseTime < 500 &&
    metrics.successRate > 0.95
  );
}

module.exports = { canaryDeployment };
```

## å®è·µç»ƒä¹ 

### ç»ƒä¹ 1: å¤šç¯å¢ƒéƒ¨ç½²é…ç½®

åˆ›å»ºå®Œæ•´çš„å¤šç¯å¢ƒé…ç½®å¹¶å®ç°è‡ªåŠ¨åŒ–éƒ¨ç½²:

```javascript
// ä»»åŠ¡:
// 1. é…ç½®å¼€å‘ã€æµ‹è¯•ã€é¢„ç”Ÿäº§å’Œç”Ÿäº§ç¯å¢ƒ
// 2. å®ç°ç¯å¢ƒç‰¹å®šçš„éƒ¨ç½²è„šæœ¬
// 3. åˆ›å»ºéƒ¨ç½²éªŒè¯æµç¨‹
// 4. å®ç°éƒ¨ç½²å›æ»šæœºåˆ¶
```

### ç»ƒä¹ 2: CI/CD æµæ°´çº¿

å®ç°å®Œæ•´çš„ CI/CD æµæ°´çº¿:

```yaml
# ä»»åŠ¡:
# 1. åˆ›å»ºæµ‹è¯•ç½‘è‡ªåŠ¨éƒ¨ç½²å·¥ä½œæµ
# 2. åˆ›å»ºä¸»ç½‘æ‰‹åŠ¨å®¡æ‰¹éƒ¨ç½²å·¥ä½œæµ
# 3. å®ç°éƒ¨ç½²åè‡ªåŠ¨éªŒè¯
# 4. é…ç½®éƒ¨ç½²é€šçŸ¥
```

### ç»ƒä¹ 3: è“ç»¿éƒ¨ç½²

å®ç°è“ç»¿éƒ¨ç½²ç­–ç•¥:

```javascript
// ä»»åŠ¡:
// 1. åˆ›å»ºåˆçº¦æ³¨å†Œè¡¨
// 2. å®ç°è“ç»¿éƒ¨ç½²è„šæœ¬
// 3. å®ç°æµé‡åˆ‡æ¢
// 4. å®ç°å¥åº·æ£€æŸ¥å’Œè‡ªåŠ¨å›æ»š
```

## å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£å¤šç¯å¢ƒéƒ¨ç½²ç­–ç•¥
- [ ] èƒ½å¤Ÿé…ç½®ä¸åŒç¯å¢ƒçš„å‚æ•°
- [ ] æŒæ¡ Hardhat Deploy æ’ä»¶ä½¿ç”¨
- [ ] èƒ½å¤Ÿç¼–å†™éƒ¨ç½²è„šæœ¬å’Œå·¥å…·å‡½æ•°
- [ ] ç†è§£ GitHub Actions éƒ¨ç½²å·¥ä½œæµ
- [ ] èƒ½å¤Ÿå®ç°éƒ¨ç½²éªŒè¯æµç¨‹
- [ ] æŒæ¡éƒ¨ç½²å›æ»šæœºåˆ¶
- [ ] ç†è§£è“ç»¿éƒ¨ç½²å’Œé‡‘ä¸é›€å‘å¸ƒ
- [ ] èƒ½å¤Ÿå®ç°è‡ªåŠ¨åŒ–éƒ¨ç½²æµç¨‹
- [ ] æŒæ¡å¯†é’¥å’Œé…ç½®ç®¡ç†

## æ‰©å±•é˜…è¯»

- [Hardhat Deploy æ–‡æ¡£](https://github.com/wighawag/hardhat-deploy)
- [GitHub Actions æ–‡æ¡£](https://docs.github.com/en/actions)
- [è“ç»¿éƒ¨ç½²æœ€ä½³å®è·µ](https://martinfowler.com/bliki/BlueGreenDeployment.html)
- [é‡‘ä¸é›€å‘å¸ƒç­–ç•¥](https://martinfowler.com/bliki/CanaryRelease.html)

## ä¸‹èŠ‚é¢„å‘Š

ä¸‹ä¸€èŠ‚æˆ‘ä»¬å°†å­¦ä¹ **åˆçº¦æºç éªŒè¯ä¸å‰ç«¯éƒ¨ç½²**,åŒ…æ‹¬:
- Etherscan æºç éªŒè¯
- å¤šåŒºå—é“¾æµè§ˆå™¨éªŒè¯
- å‰ç«¯åº”ç”¨éƒ¨ç½²
- IPFS éƒ¨ç½²
- CDN é…ç½®å’Œä¼˜åŒ–
